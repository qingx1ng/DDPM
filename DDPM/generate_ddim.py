"""
generate_ddim_imgs.py
 ä½¿ç”¨ DDIM é‡‡æ ·æ–¹å¼æ‰¹é‡ç”Ÿæˆå›¾åƒï¼Œå¹¶ä¿å­˜åˆ°æœ¬åœ°ç›®å½•ã€‚
"""

import os
import time
import math
from pathlib import Path

import torch
from torchvision.utils import save_image
from tqdm import tqdm

from denoising_diffusion_pytorch import Unet, GaussianDiffusion


# ------------------------------------------------------------------
#                         ğŸ§© å‚æ•°é…ç½®
# ------------------------------------------------------------------
ckpt_path       = '/home/featurize/work/denoising-diffusion-pytorch/results/model-25.pt'
device          = 'cuda' if torch.cuda.is_available() else 'cpu'
save_dir        = Path('ddim_imgs')

total_images    = 302       # âœ… ä½ å¯ä»¥åœ¨è¿™é‡ŒæŒ‡å®šæ€»å…±è¦ç”Ÿæˆå¤šå°‘å¼ å›¾ç‰‡
batch_size      = 16         # ä¸€æ¬¡ç”Ÿæˆå¤šå°‘å¼ ï¼Œå»ºè®® <= æ˜¾å­˜å®¹é‡å…è®¸çš„æœ€å¤§å€¼
image_size      = 128        # å›¾åƒå°ºå¯¸ï¼ˆéœ€ä¸ä½ è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰

timesteps       = 1000       # è®­ç»ƒæ—¶ä½¿ç”¨çš„æ‰©æ•£æ­¥æ•°
sampling_steps  = 50         # DDIM é‡‡æ ·æ­¥æ•°ï¼ˆè¶Šå°‘è¶Šå¿«ï¼Œé€šå¸¸ 20~100ï¼‰
ddim_eta        = 0.0        # DDIM å‚æ•°ï¼Œè®¾ä¸º 0 è¡¨ç¤ºç¡®å®šæ€§é‡‡æ ·
seed            = None         # å¯è®¾ä¸º None è¡¨ç¤ºæ¯æ¬¡éšæœºï¼›è®¾ç½®æ•°å­—è¡¨ç¤ºå¯å¤ç°
# ------------------------------------------------------------------


def load_model(checkpoint_path: str, device: str = 'cuda'):
    model = Unet(
        dim=64,
        dim_mults=(1, 2, 4, 8),
        flash_attn=False
    ).to(device)

    diffusion = GaussianDiffusion(
        model,
        image_size=image_size,
        timesteps=timesteps,
        sampling_timesteps=sampling_steps,
        ddim_sampling_eta=ddim_eta
    ).to(device)

    data = torch.load(checkpoint_path, map_location=device)
    state = data['model']
    to_load = {}
    for k,v in state.items():
        if k.startswith('model.'):
            new_k = k[len('model.'):]
            to_load[new_k] = v
    model.load_state_dict(to_load)
    model.eval()
    return diffusion


@torch.inference_mode()
def generate_and_save_images(diffusion, total_images, batch_size, save_dir):
    save_dir.mkdir(parents=True, exist_ok=True)
    pad_width = len(str(total_images))
    produced = 0
    t0 = time.time()

    print(f"ğŸš€ å¼€å§‹ DDIM é‡‡æ ·ï¼Œå…±éœ€ç”Ÿæˆ {total_images} å¼ å›¾ç‰‡ï¼Œæ¯æ‰¹ {batch_size} å¼ ")

    pbar = tqdm(total=total_images, unit="img")
    while produced < total_images:
        cur_bs = min(batch_size, total_images - produced)
        shape = (cur_bs, 3, image_size, image_size)

        samples = diffusion.ddim_sample(shape, return_all_timesteps=False)
        samples = samples.clamp(0., 1.)

        for i in range(cur_bs):
            img_path = save_dir / f"{produced + i:0{pad_width}d}.png"
            save_image(samples[i], img_path)

        produced += cur_bs
        pbar.update(cur_bs)

    pbar.close()
    print(f"âœ… å®Œæˆï¼{total_images} å¼ å›¾åƒå·²ä¿å­˜è‡³ã€Œ{save_dir.resolve()}ã€ï¼Œè€—æ—¶ {time.time() - t0:.1f}s")


def main():
    if seed is not None:
        torch.manual_seed(seed)

    diffusion = load_model(ckpt_path, device)
    generate_and_save_images(diffusion, total_images, batch_size, save_dir)


if __name__ == '__main__':
    main()
