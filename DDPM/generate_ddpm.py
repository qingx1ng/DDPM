"""
    ddpmç”Ÿæˆå’Œæµ‹è¯•é›†ä¸€æ ·æ•°é‡çš„å›¾åƒ
"""
import math, os, time
import torch
from torchvision.utils import save_image
from pathlib import Path
from denoising_diffusion_pytorch import Unet, GaussianDiffusion

# ------------------------------------------------------------------
#                         ğŸ§© å‚æ•°é…ç½®
# ------------------------------------------------------------------
ckpt_path = '/home/featurize/work/denoising-diffusion-pytorch/results/model-30.pt'
device = 'cuda' if torch.cuda.is_available() else 'cpu'
total_images = 302               # æ€»å…±è¦ç”Ÿæˆå¤šå°‘å¼ å›¾åƒ
batch_size = 16                    # æ¯æ‰¹ç”Ÿæˆå¤šå°‘å¼ 
save_dir = Path("ddpm_imgs")       # ä¿å­˜ç›®å½•
image_size = 128                   # ç”Ÿæˆå›¾åƒçš„åˆ†è¾¨ç‡ï¼ˆå¿…é¡»ä¸ä½ è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
sampling_timesteps = 250          # é‡‡æ ·æ­¥æ•°ï¼ˆè¶Šå°‘è¶Šå¿«ï¼‰
timesteps = 1000                  # è®­ç»ƒæ—¶è®¾ç½®çš„æ€»æ‰©æ•£æ­¥æ•°

# ======== åŠ è½½æ¨¡å‹ ========
def load_model(ckpt_path, device):
    model = Unet(
        dim=64,
        dim_mults=(1, 2, 4, 8),
        flash_attn=False
    ).to(device)

    diffusion = GaussianDiffusion(
        model,
        image_size=image_size,
        timesteps=timesteps,
        sampling_timesteps=sampling_timesteps
    ).to(device)
    state = torch.load(ckpt_path, map_location=device)['model']
    to_load = {}
    for k,v in state.items():
        if k.startswith('model.'):
            new_k = k[len('model.'):]
            to_load[new_k] = v
    model.load_state_dict(to_load)
    model.eval()
    return diffusion

# ======== æ‰¹é‡ç”Ÿæˆå›¾åƒå¹¶ä¿å­˜ ========
@torch.inference_mode()
def generate_images(diffusion, total_images, batch_size, save_dir):
    save_dir.mkdir(parents=True, exist_ok=True)
    pad = len(str(total_images))
    idx = 0

    print(f"å¼€å§‹ç”Ÿæˆ {total_images} å¼ å›¾åƒï¼Œä¿å­˜åˆ° {save_dir.resolve()}")
    t0 = time.time()

    while idx < total_images:
        cur_bs = min(batch_size, total_images - idx)
        samples = diffusion.sample(batch_size=cur_bs)
        samples = samples.clamp(0., 1.)

        for i in range(cur_bs):
            img_path = save_dir / f"{idx + i:0{pad}d}.png"
            save_image(samples[i], img_path)

        idx += cur_bs
        print(f"  -> å·²ç”Ÿæˆ {idx}/{total_images} å¼ ", end='\r', flush=True)

    print(f"\nâœ… ç”Ÿæˆå®Œæˆï¼è€—æ—¶ {time.time() - t0:.1f}s")

# ======== ä¸»ç¨‹åºå…¥å£ ========
if __name__ == '__main__':
    diffusion = load_model(ckpt_path, device)
    generate_images(diffusion, total_images, batch_size, save_dir)
